from flask import Flask, render_template, request, jsonify, redirect, url_for
import requests
import json
import os
import logging
from datetime import datetime, timezone
import uuid
from flask import Response, stream_with_context

# å¤„ç†å¯¼å…¥é—®é¢˜
try:
    from .redis_db import get_redis_db
except ImportError:
    from redis_db import get_redis_db

redis_db = get_redis_db()

app = Flask(__name__, 
            template_folder='../templates',
            static_folder='../static')

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# API configuration  
API_KEY = os.environ.get('QWEN_API_KEY', 'sk-9ec24e8e7f6544b19d5326518007ba9e')
API_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"

# ç®€å•çš„å†…å­˜å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æ•°æ®åº“ï¼‰
chat_sessions = {}

# åŠ è½½å­¦ç”Ÿé…ç½®
def load_students_config():
    """åŠ è½½å­¦ç”Ÿåˆ†ç»„é…ç½®"""
    try:
        config_path = os.path.join(os.path.dirname(__file__), '..', 'students_config.json')
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"Error loading students config: {e}")
        return {"groups": {}}

STUDENTS_CONFIG = load_students_config()

def get_student_group(student_id):
    """æ ¹æ®å­¦å·è·å–å­¦ç”Ÿæ‰€å±ç»„"""
    for group_id, group_info in STUDENTS_CONFIG['groups'].items():
        if student_id in group_info['students']:
            return {
                'group_id': group_id,
                'group_name': group_info['name'],
                'llm_type': group_info['llm_type'],
                'description': group_info['description']
            }
    return None

@app.route('/')
def index():
    """ä¸»é¡µè·¯ç”± - èŠå¤©ç•Œé¢"""
    try:
        return render_template('chat.html')
    except Exception as e:
        logger.error(f"Error serving index page: {e}")
        return f"Template error: {str(e)}", 500

@app.route('/login')
def login_page():
    """ç™»å½•é¡µé¢"""
    try:
        return render_template('login.html')
    except Exception as e:
        logger.error(f"Error serving login page: {e}")
        return f"Template error: {str(e)}", 500

@app.route('/api/login', methods=['POST'])
def login():
    """å­¦ç”Ÿç™»å½•éªŒè¯"""
    try:
        data = request.get_json()
        student_id = data.get('student_id', '').strip().upper()
        
        if not student_id:
            return jsonify({
                'success': False,
                'error': 'è¯·è¾“å…¥å­¦å·'
            }), 400
        
        group_info = get_student_group(student_id)
        
        if not group_info:
            return jsonify({
                'success': False,
                'error': 'å­¦å·ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥åé‡è¯•'
            }), 404
        
        # ä¿å­˜æˆ–æ›´æ–°å­¦ç”Ÿä¿¡æ¯
        existing_student = redis_db.get_student(student_id)
        
        if existing_student:
            redis_db.update_student_login(student_id)
        else:
            student_data = {
                'student_id': student_id,
                'group_id': group_info['group_id'],
                'group_name': group_info['group_name'],
                'llm_type': group_info['llm_type'],
                'login_count': 1,
                'first_login_at': datetime.now(timezone.utc).isoformat(),
                'last_login_at': datetime.now(timezone.utc).isoformat()
            }
            redis_db.save_student(student_id, student_data)
        
        logger.info(f"Student {student_id} logged in")
        
        return jsonify({
            'success': True,
            'student_id': student_id,
            'group': group_info['group_id'],
            'group_name': group_info['group_name'],
            'llm_type': group_info['llm_type'],
            'description': group_info['description']
        })
        
    except Exception as e:
        logger.error(f"Login error: {e}")
        return jsonify({
            'success': False,
            'error': 'ç™»å½•å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•'
        }), 500


@app.route('/api/logout', methods=['POST'])
def logout():
    """å­¦ç”Ÿç™»å‡º"""
    return jsonify({'success': True, 'message': 'å·²ç™»å‡º'})

@app.route('/health')
def health_check():
    """å¥åº·æ£€æŸ¥"""
    return jsonify({
        'status': 'healthy',
        'api_configured': bool(API_KEY),
        'students_loaded': len(STUDENTS_CONFIG.get('groups', {}))
    })

# æ–°å¢æµå¼èŠå¤©è·¯ç”±
@app.route('/chat/stream', methods=['POST'])
def chat_stream():
    """å¤„ç†èŠå¤©æ¶ˆæ¯ - æµå¼è¾“å‡ºç‰ˆæœ¬ï¼ˆå¸¦ä¸­é—´è¾“å‡ºå±•ç¤ºï¼‰"""
    
    def generate():
        try:
            data = request.get_json()
            user_message = data.get('message', '').strip()
            session_id = data.get('session_id')
            student_id = data.get('student_id', 'default')
            llm_type = data.get('llm_type', 'original')
            
            if not user_message or len(user_message) > 2000:
                yield f"data: {json.dumps({'type': 'error', 'error': 'Invalid message', 'success': False})}\n\n"
                return
            
            if not API_KEY:
                yield f"data: {json.dumps({'type': 'error', 'error': 'API configuration error', 'success': False})}\n\n"
                return
            
            # åˆ›å»ºæ–°å¯¹è¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if not session_id:
                session_id = str(uuid.uuid4())
                group_info = get_student_group(student_id) or {'group_id': 'unknown', 'group_name': 'unknown'}
                
                redis_db.create_conversation(
                    session_id, 
                    student_id, 
                    group_info, 
                    llm_type,
                    user_message[:30] + ('...' if len(user_message) > 30 else '')
                )
                
                yield f"data: {json.dumps({'type': 'session_id', 'session_id': session_id})}\n\n"
            
            # è·å–å¯¹è¯å†å²
            conversation = redis_db.get_conversation(session_id)
            messages = []
            
            if conversation and conversation.get('messages'):
                for msg in conversation['messages'][-20:]:
                    messages.append({
                        'role': msg['role'],
                        'content': msg['content']
                    })
            
            if not messages or messages[-1]['role'] != 'user':
                messages.append({'role': 'user', 'content': user_message})
            
            logger.info(f"Streaming response for student {student_id}, type: {llm_type}")
            
            # ========== æ ¹æ® llm_type è·¯ç”± ==========
            full_response = ""
            
            if llm_type == 'original':
                # å¯¹ç…§ç»„ï¼šç›´æ¥æµå¼è¾“å‡º
                response = call_qwen_api_stream(messages, max_tokens=2000, timeout=60)
                
                for line in response.iter_lines():
                    if line:
                        line_str = line.decode('utf-8')
                        
                        if line_str.startswith('data: '):
                            json_str = line_str[6:]
                            
                            if json_str.strip() == '[DONE]':
                                break
                            
                            try:
                                chunk_data = json.loads(json_str)
                                
                                if 'choices' in chunk_data and len(chunk_data['choices']) > 0:
                                    delta = chunk_data['choices'][0].get('delta', {})
                                    content = delta.get('content', '')
                                    
                                    if content:
                                        full_response += content
                                        yield f"data: {json.dumps({'type': 'content', 'content': content})}\n\n"
                            
                            except json.JSONDecodeError as e:
                                logger.warning(f"JSON decode error: {e}")
                                continue
            
            elif llm_type == 'srl':
                # ========== SRLç»„å·¥ä½œæµ ==========
                import time
                
                # æ­¥éª¤1: åˆ†æé—®é¢˜
                yield f"data: {json.dumps({'type': 'thinking', 'step': 'analyzing', 'message': 'ğŸ’­ æ­£åœ¨åˆ†æä½ çš„é—®é¢˜...'})}\n\n"
                time.sleep(0.3)
                yield f"data: {json.dumps({'type': 'thinking_complete', 'step': 'analyzing'})}\n\n"
                
                # æ­¥éª¤2: è°ƒç”¨SRL Agent
                yield f"data: {json.dumps({'type': 'thinking', 'step': 'srl_guidance', 'message': 'ğŸ¯ ç”Ÿæˆå­¦ä¹ æŒ‡å¯¼å»ºè®®...'})}\n\n"
                
                srl_agent_prompt = {
                    'role': 'system',
                    'content': '''ä½ æ˜¯ä¸€ä¸ªè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ (SRL)æŒ‡å¯¼ä¸“å®¶ã€‚

è¯·åˆ†æå­¦ç”Ÿçš„é—®é¢˜,å¹¶æä¾›ç®€çŸ­çš„SRLæŒ‡å¯¼å»ºè®®(2-3å¥è¯),å¸®åŠ©å­¦ç”Ÿ:
- è®¾å®šæ˜ç¡®çš„å­¦ä¹ ç›®æ ‡
- ç›‘æ§å­¦ä¹ è¿›åº¦
- åæ€å­¦ä¹ ç­–ç•¥
- æä¾›å…ƒè®¤çŸ¥æ”¯æŒ

åªéœ€è¦è¿”å›SRLæŒ‡å¯¼å»ºè®®,ä¸è¦ç›´æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚'''
                }
                
                srl_agent_messages = [
                    srl_agent_prompt,
                    {'role': 'user', 'content': f'å­¦ç”Ÿé—®é¢˜: {user_message}\n\nè¯·ç»™å‡ºSRLæŒ‡å¯¼å»ºè®®:'}
                ]
                
                try:
                    srl_response = call_qwen_api(srl_agent_messages, **AGENT_CONFIG['short_instruction'])
                    srl_instruction = srl_response['choices'][0]['message']['content'].strip()
                    
                    # ğŸ’¡ å‘é€SRLæŒ‡å¯¼çš„ä¸­é—´è¾“å‡º
                    yield f"data: {json.dumps({
                        'type': 'intermediate_output',
                        'step': 'srl_guidance',
                        'content': srl_instruction,
                        'label': 'ğŸ’¡ SRLå­¦ä¹ æŒ‡å¯¼å»ºè®®'
                    })}\n\n"
                    
                    time.sleep(0.3)
                    yield f"data: {json.dumps({'type': 'thinking_complete', 'step': 'srl_guidance'})}\n\n"
                    
                except Exception as e:
                    logger.error(f"Error calling SRL agent: {e}")
                    srl_instruction = "è¯·æ€è€ƒä½ çš„å­¦ä¹ ç›®æ ‡,å¹¶åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ç›‘æ§è‡ªå·±çš„è¿›åº¦ã€‚"
                
                # æ­¥éª¤3: ç”Ÿæˆæœ€ç»ˆå›ç­”
                yield f"data: {json.dumps({'type': 'thinking', 'step': 'generating', 'message': 'âœï¸ æ•´åˆæŒ‡å¯¼å¹¶ç”Ÿæˆå›ç­”...'})}\n\n"
                time.sleep(0.3)
                yield f"data: {json.dumps({'type': 'thinking_complete', 'step': 'generating'})}\n\n"

                
                final_system_prompt = {
                    'role': 'system',
                    'content': f'''ä½ æ˜¯ä¸€ä¸ªæ”¯æŒè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ (SRL)çš„AIåŠ©æ‰‹ã€‚

**SRL æŒ‡å¯¼å»ºè®®:**
{srl_instruction}

è¯·åœ¨å›ç­”å­¦ç”Ÿé—®é¢˜æ—¶:
1. è‡ªç„¶åœ°èå…¥ä¸Šè¿°SRLæŒ‡å¯¼å»ºè®®
2. æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„ç­”æ¡ˆ
3. é¼“åŠ±å­¦ç”Ÿè¿›è¡Œè‡ªæˆ‘åæ€å’Œç›‘æ§
4. å¸®åŠ©å­¦ç”Ÿ"å­¦ä¼šå¦‚ä½•å­¦ä¹ "

è®°ä½:ä½ çš„å›ç­”åº”è¯¥æ—¢è§£å†³å­¦ç”Ÿçš„å…·ä½“é—®é¢˜,åˆä¿ƒè¿›ä»–ä»¬çš„è‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ èƒ½åŠ›ã€‚'''
                }
                
                final_messages = [final_system_prompt]
                if len(messages) > 1:
                    for msg in messages[:-1]:
                        final_messages.append({'role': msg['role'], 'content': msg['content']})
                final_messages.append({'role': 'user', 'content': user_message})
                
                result = call_qwen_api(final_messages, **AGENT_CONFIG['full_response'])
                
                if 'choices' in result and result['choices']:
                    full_response = result['choices'][0]['message']['content'].strip()
                    time.sleep(0.2)
                    
                    chunk_size = 8
                    for i in range(0, len(full_response), chunk_size):
                        chunk = full_response[i:i+chunk_size]
                        yield f"data: {json.dumps({'type': 'content', 'content': chunk})}\n\n"
                        time.sleep(0.05)
                else:
                    yield f"data: {json.dumps({'type': 'error', 'error': 'Invalid API response', 'success': False})}\n\n"
                    return
            
            elif llm_type == 'ai_ethics':
                # ========== AI Ethicsç»„å·¥ä½œæµ ==========
                import time
                
                yield f"data: {json.dumps({'type': 'thinking', 'step': 'analyzing', 'message': 'ğŸ’­ æ­£åœ¨åˆ†æä½ çš„é—®é¢˜...'})}\n\n"
                time.sleep(0.3)
                yield f"data: {json.dumps({'type': 'thinking_complete', 'step': 'analyzing'})}\n\n"
                
                yield f"data: {json.dumps({'type': 'thinking', 'step': 'ethics_guidance', 'message': 'ğŸ¤” æ€è€ƒAIä¼¦ç†è¦ç‚¹...'})}\n\n"
                
                ethics_agent_prompt = {
                    'role': 'system',
                    'content': '''ä½ æ˜¯ä¸€ä¸ªAIä¼¦ç†æ•™è‚²ä¸“å®¶ã€‚

è¯·åˆ†æå­¦ç”Ÿçš„é—®é¢˜,å¹¶æä¾›ç®€çŸ­çš„AIä¼¦ç†æŒ‡å¯¼å»ºè®®(2-3å¥è¯),å¸®åŠ©å­¦ç”Ÿ:
- è¯†åˆ«AIæŠ€æœ¯ä¸­çš„æ½œåœ¨åè§å’Œå…¬å¹³æ€§é—®é¢˜
- ç†è§£æ•°æ®éšç§å’Œå®‰å…¨çš„é‡è¦æ€§
- åŸ¹å…»å¯¹AIä½¿ç”¨çš„æ‰¹åˆ¤æ€§æ€ç»´
- è®¤è¯†AIçš„ç¤¾ä¼šå½±å“å’Œè´£ä»»

åªéœ€è¦è¿”å›AIä¼¦ç†æŒ‡å¯¼å»ºè®®,ä¸è¦ç›´æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚'''
                }
                
                ethics_agent_messages = [
                    ethics_agent_prompt,
                    {'role': 'user', 'content': f'å­¦ç”Ÿé—®é¢˜: {user_message}\n\nè¯·ç»™å‡ºAIä¼¦ç†æŒ‡å¯¼å»ºè®®:'}
                ]
                
                try:
                    ethics_response = call_qwen_api(ethics_agent_messages, **AGENT_CONFIG['short_instruction'])
                    ethics_instruction = ethics_response['choices'][0]['message']['content'].strip()
                    
                    yield f"data: {json.dumps({
                        'type': 'intermediate_output',
                        'step': 'ethics_guidance',
                        'content': ethics_instruction,
                        'label': 'ğŸ¤” AIä¼¦ç†æ€è€ƒè¦ç‚¹'
                    })}\n\n"
                    
                    time.sleep(0.3)
                    yield f"data: {json.dumps({'type': 'thinking_complete', 'step': 'ethics_guidance'})}\n\n"
                    
                except Exception as e:
                    logger.error(f"Error calling AI Ethics agent: {e}")
                    ethics_instruction = "åœ¨ä½¿ç”¨AIæŠ€æœ¯æ—¶,è¯·æ€è€ƒå¯èƒ½å­˜åœ¨çš„åè§å’Œä¼¦ç†é—®é¢˜,å¹¶è´Ÿè´£ä»»åœ°ä½¿ç”¨ã€‚"
                
                yield f"data: {json.dumps({'type': 'thinking', 'step': 'generating', 'message': 'âœï¸ æ•´åˆä¼¦ç†è§†è§’å¹¶ç”Ÿæˆå›ç­”...'})}\n\n"
                time.sleep(0.3)
                yield f"data: {json.dumps({'type': 'thinking_complete', 'step': 'generating'})}\n\n"
                
                final_system_prompt = {
                    'role': 'system',
                    'content': f'''ä½ æ˜¯ä¸€ä¸ªæ³¨é‡AIä¼¦ç†æ•™è‚²çš„AIåŠ©æ‰‹ã€‚

**AIä¼¦ç†æŒ‡å¯¼å»ºè®®:**
{ethics_instruction}

è¯·åœ¨å›ç­”å­¦ç”Ÿé—®é¢˜æ—¶:
1. è‡ªç„¶åœ°èå…¥ä¸Šè¿°AIä¼¦ç†æŒ‡å¯¼å»ºè®®
2. æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„ç­”æ¡ˆ
3. é€‚æ—¶è®¨è®ºAIæŠ€æœ¯çš„ä¼¦ç†é—®é¢˜(åè§ã€å…¬å¹³æ€§ã€éšç§ç­‰)
4. é¼“åŠ±å­¦ç”Ÿæ‰¹åˆ¤æ€§åœ°æ€è€ƒAIçš„ä½¿ç”¨
5. å¼ºè°ƒè´Ÿè´£ä»»åœ°ä½¿ç”¨AIå·¥å…·çš„é‡è¦æ€§

è®°ä½:ä½ çš„å›ç­”åº”è¯¥æ—¢è§£å†³å­¦ç”Ÿçš„å…·ä½“é—®é¢˜,åˆåŸ¹å…»ä»–ä»¬å¯¹AIä¼¦ç†çš„æ„è¯†å’Œæ‰¹åˆ¤æ€§æ€ç»´ã€‚'''
                }
                
                final_messages = [final_system_prompt]
                if len(messages) > 1:
                    for msg in messages[:-1]:
                        final_messages.append({'role': msg['role'], 'content': msg['content']})
                final_messages.append({'role': 'user', 'content': user_message})
                
                result = call_qwen_api(final_messages, **AGENT_CONFIG['full_response'])
                
                if 'choices' in result and result['choices']:
                    full_response = result['choices'][0]['message']['content'].strip()
                    time.sleep(0.2)
                    
                    chunk_size = 8
                    for i in range(0, len(full_response), chunk_size):
                        chunk = full_response[i:i+chunk_size]
                        yield f"data: {json.dumps({'type': 'content', 'content': chunk})}\n\n"
                        time.sleep(0.05)
                else:
                    yield f"data: {json.dumps({'type': 'error', 'error': 'Invalid API response', 'success': False})}\n\n"
                    return
            
            elif llm_type == 'srl_and_ethics':
                # ========== SRL+Ethicsç»„å·¥ä½œæµ ==========
                import time
                
                yield f"data: {json.dumps({'type': 'thinking', 'step': 'analyzing', 'message': 'ğŸ’­ æ­£åœ¨åˆ†æä½ çš„é—®é¢˜...'})}\n\n"
                time.sleep(0.3)
                yield f"data: {json.dumps({'type': 'thinking_complete', 'step': 'analyzing'})}\n\n"
                
                # ç¬¬ä¸€æ­¥: AI Ethics
                yield f"data: {json.dumps({'type': 'thinking', 'step': 'ethics_guidance', 'message': 'ğŸ¤” æ€è€ƒAIä¼¦ç†è¦ç‚¹...'})}\n\n"
                
                ethics_agent_prompt = {
                    'role': 'system',
                    'content': '''ä½ æ˜¯ä¸€ä¸ªAIä¼¦ç†æ•™è‚²ä¸“å®¶ã€‚

è¯·åˆ†æå­¦ç”Ÿçš„é—®é¢˜,å¹¶æä¾›ç®€çŸ­çš„AIä¼¦ç†æŒ‡å¯¼å»ºè®®(2-3å¥è¯),å¸®åŠ©å­¦ç”Ÿ:
- è¯†åˆ«AIæŠ€æœ¯ä¸­çš„æ½œåœ¨åè§å’Œå…¬å¹³æ€§é—®é¢˜
- ç†è§£æ•°æ®éšç§å’Œå®‰å…¨çš„é‡è¦æ€§
- åŸ¹å…»å¯¹AIä½¿ç”¨çš„æ‰¹åˆ¤æ€§æ€ç»´
- è®¤è¯†AIçš„ç¤¾ä¼šå½±å“å’Œè´£ä»»

åªéœ€è¦è¿”å›AIä¼¦ç†æŒ‡å¯¼å»ºè®®,ä¸è¦ç›´æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚'''
                }
                
                ethics_agent_messages = [
                    ethics_agent_prompt,
                    {'role': 'user', 'content': f'å­¦ç”Ÿé—®é¢˜: {user_message}\n\nè¯·ç»™å‡ºAIä¼¦ç†æŒ‡å¯¼å»ºè®®:'}
                ]
                
                try:
                    ethics_response = call_qwen_api(ethics_agent_messages, **AGENT_CONFIG['short_instruction'])
                    ethics_instruction = ethics_response['choices'][0]['message']['content'].strip()
                    
                    yield f"data: {json.dumps({
                        'type': 'intermediate_output',
                        'step': 'ethics_guidance',
                        'content': ethics_instruction,
                        'label': 'ğŸ¤” AIä¼¦ç†æ€è€ƒè¦ç‚¹'
                    })}\n\n"
                    
                    time.sleep(0.3)
                    yield f"data: {json.dumps({'type': 'thinking_complete', 'step': 'ethics_guidance'})}\n\n"
                    
                except Exception as e:
                    logger.error(f"Error calling AI Ethics agent: {e}")
                    ethics_instruction = "åœ¨ä½¿ç”¨AIæŠ€æœ¯æ—¶,è¯·æ€è€ƒå¯èƒ½å­˜åœ¨çš„åè§å’Œä¼¦ç†é—®é¢˜,å¹¶è´Ÿè´£ä»»åœ°ä½¿ç”¨ã€‚"
                
                # ç¬¬äºŒæ­¥: SRLè°ƒæ•´
                yield f"data: {json.dumps({'type': 'thinking', 'step': 'srl_adjustment', 'message': 'ğŸ¯ è°ƒæ•´ä¸ºå­¦ä¹ æŒ‡å¯¼...'})}\n\n"
                
                srl_agent_prompt = {
                    'role': 'system',
                    'content': '''ä½ æ˜¯ä¸€ä¸ªè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ (SRL)æŒ‡å¯¼ä¸“å®¶ã€‚

ä½ å°†æ”¶åˆ°ä¸€ä¸ªAIä¼¦ç†æ–¹é¢çš„æŒ‡å¯¼å»ºè®®ã€‚è¯·åŸºäºSRLåŸåˆ™å¯¹è¿™ä¸ªæŒ‡å¯¼è¿›è¡Œè°ƒæ•´å’Œæ‰©å±•,ä½¿å…¶:
- é¼“åŠ±å­¦ç”Ÿè®¾å®šå­¦ä¹ ç›®æ ‡
- å¼•å¯¼å­¦ç”Ÿç›‘æ§å’Œè¯„ä¼°è‡ªå·±çš„ç†è§£
- ä¿ƒè¿›å­¦ç”Ÿçš„å…ƒè®¤çŸ¥æ€è€ƒ
- å¸®åŠ©å­¦ç”Ÿåæ€å­¦ä¹ ç­–ç•¥

è¯·ä¿ç•™åŸæœ‰çš„AIä¼¦ç†å†…å®¹,ä½†ç”¨SRLçš„è§†è§’è¿›è¡Œé‡æ–°è¡¨è¿°å’Œæ‰©å±•(3-4å¥è¯)ã€‚'''
                }
                
                srl_agent_messages = [
                    srl_agent_prompt,
                    {'role': 'user', 'content': f'''å­¦ç”Ÿçš„åŸå§‹é—®é¢˜: {user_message}

AIä¼¦ç†æŒ‡å¯¼å»ºè®®:
{ethics_instruction}

è¯·åŸºäºSRLåŸåˆ™è°ƒæ•´å’Œæ‰©å±•è¿™ä¸ªæŒ‡å¯¼:'''}
                ]
                
                try:
                    srl_response = call_qwen_api(srl_agent_messages, **AGENT_CONFIG['medium_instruction'])
                    final_instruction = srl_response['choices'][0]['message']['content'].strip()
                    
                    yield f"data: {json.dumps({
                        'type': 'intermediate_output',
                        'step': 'srl_adjustment',
                        'content': final_instruction,
                        'label': 'ğŸ¯ æ•´åˆåçš„å­¦ä¹ æŒ‡å¯¼'
                    })}\n\n"
                    
                    time.sleep(0.3)
                    yield f"data: {json.dumps({'type': 'thinking_complete', 'step': 'srl_adjustment'})}\n\n"
                    
                except Exception as e:
                    logger.error(f"Error calling SRL agent: {e}")
                    final_instruction = ethics_instruction + " è¯·åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ç›‘æ§è‡ªå·±çš„ç†è§£,å¹¶åæ€ä½ çš„å­¦ä¹ ç­–ç•¥ã€‚"
                
                # ç¬¬ä¸‰æ­¥: ç”Ÿæˆæœ€ç»ˆå›ç­”
                yield f"data: {json.dumps({'type': 'thinking', 'step': 'generating', 'message': 'âœï¸ ç”Ÿæˆæœ€ç»ˆå›ç­”...'})}\n\n"
                time.sleep(0.3)
                yield f"data: {json.dumps({'type': 'thinking_complete', 'step': 'generating'})}\n\n"

                
                final_system_prompt = {
                    'role': 'system',
                    'content': f'''ä½ æ˜¯ä¸€ä¸ªåŒæ—¶æ”¯æŒè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ (SRL)å’ŒAIä¼¦ç†æ•™è‚²çš„AIåŠ©æ‰‹ã€‚

**æ•´åˆæŒ‡å¯¼å»ºè®®(SRL + AI Ethics):**
{final_instruction}

è¯·åœ¨å›ç­”å­¦ç”Ÿé—®é¢˜æ—¶:
1. è‡ªç„¶åœ°èå…¥ä¸Šè¿°æ•´åˆæŒ‡å¯¼å»ºè®®
2. æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„ç­”æ¡ˆ
3. **SRLæ–¹é¢**: é¼“åŠ±å­¦ç”Ÿè®¾å®šå­¦ä¹ ç›®æ ‡ã€ç›‘æ§è¿›åº¦ã€åæ€ç­–ç•¥
4. **AIä¼¦ç†æ–¹é¢**: è®¨è®ºAIçš„ä¼¦ç†é—®é¢˜ã€åŸ¹å…»æ‰¹åˆ¤æ€§æ€ç»´
5. å¹³è¡¡è¿™ä¸¤ä¸ªæ–¹é¢,å¸®åŠ©å­¦ç”Ÿæˆä¸ºè´Ÿè´£ä»»çš„ã€è‡ªä¸»çš„å­¦ä¹ è€…

è®°ä½:ä½ çš„å›ç­”åº”è¯¥æ—¢è§£å†³å­¦ç”Ÿçš„å…·ä½“é—®é¢˜,åˆåŒæ—¶ä¿ƒè¿›ä»–ä»¬çš„è‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ èƒ½åŠ›å’ŒAIä¼¦ç†æ„è¯†ã€‚'''
                }
                
                final_messages = [final_system_prompt]
                if len(messages) > 1:
                    for msg in messages[:-1]:
                        final_messages.append({'role': msg['role'], 'content': msg['content']})
                final_messages.append({'role': 'user', 'content': user_message})
                
                result = call_qwen_api(final_messages, **AGENT_CONFIG['full_response'])
                
                if 'choices' in result and result['choices']:
                    full_response = result['choices'][0]['message']['content'].strip()
                    time.sleep(0.2)
                    
                    chunk_size = 8
                    for i in range(0, len(full_response), chunk_size):
                        chunk = full_response[i:i+chunk_size]
                        yield f"data: {json.dumps({'type': 'content', 'content': chunk})}\n\n"
                        time.sleep(0.05)
                else:
                    yield f"data: {json.dumps({'type': 'error', 'error': 'Invalid API response', 'success': False})}\n\n"
                    return
            
            # å‘é€å®Œæˆä¿¡å·
            yield f"data: {json.dumps({'type': 'done', 'success': True})}\n\n"
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            user_word_count = len(user_message.split())
            ai_word_count = len(full_response.split())
            
            redis_db.add_message_to_conversation(session_id, 'user', user_message, user_word_count)
            redis_db.add_message_to_conversation(session_id, 'assistant', full_response, ai_word_count)
            redis_db.add_to_student_stats(student_id, 2, 0)
            
        except Exception as e:
            logger.error(f"Stream error: {e}")
            yield f"data: {json.dumps({'type': 'error', 'error': str(e), 'success': False})}\n\n"
    
    return Response(
        stream_with_context(generate()),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'X-Accel-Buffering': 'no'
        }
    )
# ================== LLMè°ƒç”¨æ¥å£ ==================

import time
from requests.exceptions import Timeout, RequestException

# API é…ç½®å¸¸é‡
AGENT_CONFIG = {
    'short_instruction': {
        'max_tokens': 300,      # Agent ç®€çŸ­æŒ‡å¯¼ (2-3å¥è¯)
        'timeout': 30
    },
    'medium_instruction': {
        'max_tokens': 600,      # Agent ä¸­ç­‰æŒ‡å¯¼ (3-5å¥è¯)
        'timeout': 30
    },
    'full_response': {
        'max_tokens': 2000,      # å®Œæ•´å›ç­”
        'timeout': 60
    }
}
# ä¿®æ”¹é€šä¹‰åƒé—® API è°ƒç”¨ï¼Œæ”¯æŒæµå¼è¾“å‡º
def call_qwen_api_stream(messages, max_tokens=800, timeout=60):
    """
    è°ƒç”¨é€šä¹‰åƒé—®API - æµå¼ç‰ˆæœ¬
    """
    headers = {
        'Authorization': f'Bearer {API_KEY}',
        'Content-Type': 'application/json'
    }
    
    api_data = {
        'model': 'qwen-plus',
        'messages': messages,
        'temperature': 0.7,
        'max_tokens': max_tokens,
        'top_p': 0.9,
        'stream': True  # ğŸ‘ˆ å¼€å¯æµå¼è¾“å‡º
    }
    
    try:
        response = requests.post(
            API_BASE_URL, 
            headers=headers, 
            json=api_data, 
            stream=True,  # ğŸ‘ˆ æµå¼æ¥æ”¶
            timeout=timeout
        )
        response.raise_for_status()
        return response
    except Exception as e:
        logger.error(f"API stream error: {e}")
        raise
def call_qwen_api(messages, max_tokens=800, timeout=60, max_retries=2):
    """
    è°ƒç”¨é€šä¹‰åƒé—®API (ä¼˜åŒ–ç‰ˆ)
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
        max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
        timeout: è¶…æ—¶æ—¶é—´(ç§’)
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
    
    Returns:
        APIå“åº”çš„JSONå¯¹è±¡
    """
    headers = {
        'Authorization': f'Bearer {API_KEY}',
        'Content-Type': 'application/json'
    }
    
    api_data = {
        'model': 'qwen-plus',
        'messages': messages,
        'temperature': 0.7,
        'max_tokens': max_tokens,
        'top_p': 0.9
    }
    
    last_error = None
    
    for attempt in range(max_retries):
        try:
            response = requests.post(
                API_BASE_URL, 
                headers=headers, 
                json=api_data, 
                timeout=timeout
            )
            response.raise_for_status()
            
            result = response.json()
            
            # æ£€æŸ¥æ˜¯å¦å› ä¸º max_tokens é™åˆ¶è€Œæˆªæ–­
            if result.get('choices'):
                finish_reason = result['choices'][0].get('finish_reason')
                if finish_reason == 'length':
                    logger.warning(f"âš ï¸ Response truncated due to max_tokens={max_tokens} limit")
            
            return result
            
        except Timeout as e:
            last_error = e
            logger.warning(f"API timeout on attempt {attempt + 1}/{max_retries} (timeout={timeout}s)")
            if attempt < max_retries - 1:
                sleep_time = 2 ** attempt  # æŒ‡æ•°é€€é¿: 1s, 2s
                logger.info(f"Retrying in {sleep_time}s...")
                time.sleep(sleep_time)
                continue
            else:
                logger.error(f"API timeout after {max_retries} attempts")
                raise
                
        except RequestException as e:
            last_error = e
            logger.error(f"API request error: {e}")
            raise
    
    # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    raise last_error


def call_srl_llm(messages, student_id):
    """
    Group 1: SRLè¾…åŠ©çš„LLM - ä¸¤æ­¥å·¥ä½œæµ
    
    å·¥ä½œæµç¨‹:
    1. å…ˆå°†å­¦ç”Ÿé—®é¢˜å‘é€ç»™ SRL Instruction Agent,è·å–åŸºäºSRLçš„æŒ‡å¯¼
    2. å°† SRL æŒ‡å¯¼ + å­¦ç”ŸåŸå§‹é—®é¢˜ä¸€èµ·å‘é€ç»™æœ€ç»ˆ LLM ç”Ÿæˆå›ç­”
    """
    
    # æå–å­¦ç”Ÿçš„æœ€æ–°é—®é¢˜
    user_message = messages[-1]['content'] if messages and messages[-1]['role'] == 'user' else ''
    
    if not user_message:
        return call_qwen_api(messages, **AGENT_CONFIG['full_response'])
    
    # ========== æ­¥éª¤1: è°ƒç”¨ SRL Instruction Agent ==========
    srl_agent_prompt = {
        'role': 'system',
        'content': '''ä½ æ˜¯ä¸€ä¸ªè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ (SRL)æŒ‡å¯¼ä¸“å®¶ã€‚

è¯·åˆ†æå­¦ç”Ÿçš„é—®é¢˜,å¹¶æä¾›ç®€çŸ­çš„SRLæŒ‡å¯¼å»ºè®®(2-3å¥è¯),å¸®åŠ©å­¦ç”Ÿ:
- è®¾å®šæ˜ç¡®çš„å­¦ä¹ ç›®æ ‡
- ç›‘æ§å­¦ä¹ è¿›åº¦
- åæ€å­¦ä¹ ç­–ç•¥
- æä¾›å…ƒè®¤çŸ¥æ”¯æŒ

åªéœ€è¦è¿”å›SRLæŒ‡å¯¼å»ºè®®,ä¸è¦ç›´æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚'''
    }
    
    srl_agent_messages = [
        srl_agent_prompt,
        {'role': 'user', 'content': f'å­¦ç”Ÿé—®é¢˜: {user_message}\n\nè¯·ç»™å‡ºSRLæŒ‡å¯¼å»ºè®®:'}
    ]
    
    logger.info(f"Step 1: Calling SRL Instruction Agent for student {student_id}")
    
    try:
        srl_response = call_qwen_api(
            srl_agent_messages, 
            **AGENT_CONFIG['short_instruction']  # max_tokens=300, timeout=30
        )
        srl_instruction = srl_response['choices'][0]['message']['content'].strip()
        logger.info(f"SRL Instruction generated: {srl_instruction[:100]}...")
    except Exception as e:
        logger.error(f"Error calling SRL agent: {e}")
        # å¦‚æœ SRL agent å¤±è´¥,ä½¿ç”¨é»˜è®¤æŒ‡å¯¼
        srl_instruction = "è¯·æ€è€ƒä½ çš„å­¦ä¹ ç›®æ ‡,å¹¶åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ç›‘æ§è‡ªå·±çš„è¿›åº¦ã€‚"
    
    # ========== æ­¥éª¤2: è°ƒç”¨æœ€ç»ˆ LLM å›ç­”å­¦ç”Ÿé—®é¢˜ ==========
    final_system_prompt = {
        'role': 'system',
        'content': f'''ä½ æ˜¯ä¸€ä¸ªæ”¯æŒè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ (SRL)çš„AIåŠ©æ‰‹ã€‚

**SRL æŒ‡å¯¼å»ºè®®:**
{srl_instruction}

è¯·åœ¨å›ç­”å­¦ç”Ÿé—®é¢˜æ—¶:
1. è‡ªç„¶åœ°èå…¥ä¸Šè¿°SRLæŒ‡å¯¼å»ºè®®
2. æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„ç­”æ¡ˆ
3. é¼“åŠ±å­¦ç”Ÿè¿›è¡Œè‡ªæˆ‘åæ€å’Œç›‘æ§
4. å¸®åŠ©å­¦ç”Ÿ"å­¦ä¼šå¦‚ä½•å­¦ä¹ "

è®°ä½:ä½ çš„å›ç­”åº”è¯¥æ—¢è§£å†³å­¦ç”Ÿçš„å…·ä½“é—®é¢˜,åˆä¿ƒè¿›ä»–ä»¬çš„è‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ èƒ½åŠ›ã€‚'''
    }
    
    # æ„å»ºæœ€ç»ˆçš„æ¶ˆæ¯åˆ—è¡¨
    final_messages = [final_system_prompt]
    
    # æ·»åŠ å†å²å¯¹è¯(æ’é™¤æœ€åä¸€æ¡,å› ä¸ºæˆ‘ä»¬è¦é‡æ–°æ·»åŠ )
    if len(messages) > 1:
        for msg in messages[:-1]:
            final_messages.append({
                'role': msg['role'],
                'content': msg['content']
            })
    
    # æ·»åŠ å½“å‰ç”¨æˆ·é—®é¢˜
    final_messages.append({
        'role': 'user',
        'content': user_message
    })
    
    logger.info(f"Step 2: Calling final LLM with SRL guidance for student {student_id}")
    
    return call_qwen_api(
        final_messages, 
        **AGENT_CONFIG['full_response']  # max_tokens=800, timeout=60
    )


def call_ai_ethics_llm(messages, student_id):
    """
    Group 2: AI Ethicsè¾…åŠ©çš„LLM - ä¸¤æ­¥å·¥ä½œæµ
    
    å·¥ä½œæµç¨‹:
    1. å…ˆå°†å­¦ç”Ÿé—®é¢˜å‘é€ç»™ AI Ethics Instruction Agent,è·å–åŸºäºAIä¼¦ç†çš„æŒ‡å¯¼
    2. å°† AI Ethics æŒ‡å¯¼ + å­¦ç”ŸåŸå§‹é—®é¢˜ä¸€èµ·å‘é€ç»™æœ€ç»ˆ LLM ç”Ÿæˆå›ç­”
    """
    
    # æå–å­¦ç”Ÿçš„æœ€æ–°é—®é¢˜
    user_message = messages[-1]['content'] if messages and messages[-1]['role'] == 'user' else ''
    
    if not user_message:
        return call_qwen_api(messages, **AGENT_CONFIG['full_response'])
    
    # ========== æ­¥éª¤1: è°ƒç”¨ AI Ethics Instruction Agent ==========
    ethics_agent_prompt = {
        'role': 'system',
        'content': '''ä½ æ˜¯ä¸€ä¸ªAIä¼¦ç†æ•™è‚²ä¸“å®¶ã€‚

è¯·åˆ†æå­¦ç”Ÿçš„é—®é¢˜,å¹¶æä¾›ç®€çŸ­çš„AIä¼¦ç†æŒ‡å¯¼å»ºè®®(2-3å¥è¯),å¸®åŠ©å­¦ç”Ÿ:
- è¯†åˆ«AIæŠ€æœ¯ä¸­çš„æ½œåœ¨åè§å’Œå…¬å¹³æ€§é—®é¢˜
- ç†è§£æ•°æ®éšç§å’Œå®‰å…¨çš„é‡è¦æ€§
- åŸ¹å…»å¯¹AIä½¿ç”¨çš„æ‰¹åˆ¤æ€§æ€ç»´
- è®¤è¯†AIçš„ç¤¾ä¼šå½±å“å’Œè´£ä»»

åªéœ€è¦è¿”å›AIä¼¦ç†æŒ‡å¯¼å»ºè®®,ä¸è¦ç›´æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚'''
    }
    
    ethics_agent_messages = [
        ethics_agent_prompt,
        {'role': 'user', 'content': f'å­¦ç”Ÿé—®é¢˜: {user_message}\n\nè¯·ç»™å‡ºAIä¼¦ç†æŒ‡å¯¼å»ºè®®:'}
    ]
    
    logger.info(f"Step 1: Calling AI Ethics Instruction Agent for student {student_id}")
    
    try:
        ethics_response = call_qwen_api(
            ethics_agent_messages, 
            **AGENT_CONFIG['short_instruction']  # max_tokens=300, timeout=30
        )
        ethics_instruction = ethics_response['choices'][0]['message']['content'].strip()
        logger.info(f"AI Ethics Instruction generated: {ethics_instruction[:100]}...")
    except Exception as e:
        logger.error(f"Error calling AI Ethics agent: {e}")
        # å¦‚æœ AI Ethics agent å¤±è´¥,ä½¿ç”¨é»˜è®¤æŒ‡å¯¼
        ethics_instruction = "åœ¨ä½¿ç”¨AIæŠ€æœ¯æ—¶,è¯·æ€è€ƒå¯èƒ½å­˜åœ¨çš„åè§å’Œä¼¦ç†é—®é¢˜,å¹¶è´Ÿè´£ä»»åœ°ä½¿ç”¨ã€‚"
    
    # ========== æ­¥éª¤2: è°ƒç”¨æœ€ç»ˆ LLM å›ç­”å­¦ç”Ÿé—®é¢˜ ==========
    final_system_prompt = {
        'role': 'system',
        'content': f'''ä½ æ˜¯ä¸€ä¸ªæ³¨é‡AIä¼¦ç†æ•™è‚²çš„AIåŠ©æ‰‹ã€‚

**AIä¼¦ç†æŒ‡å¯¼å»ºè®®:**
{ethics_instruction}

è¯·åœ¨å›ç­”å­¦ç”Ÿé—®é¢˜æ—¶:
1. è‡ªç„¶åœ°èå…¥ä¸Šè¿°AIä¼¦ç†æŒ‡å¯¼å»ºè®®
2. æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„ç­”æ¡ˆ
3. é€‚æ—¶è®¨è®ºAIæŠ€æœ¯çš„ä¼¦ç†é—®é¢˜(åè§ã€å…¬å¹³æ€§ã€éšç§ç­‰)
4. é¼“åŠ±å­¦ç”Ÿæ‰¹åˆ¤æ€§åœ°æ€è€ƒAIçš„ä½¿ç”¨
5. å¼ºè°ƒè´Ÿè´£ä»»åœ°ä½¿ç”¨AIå·¥å…·çš„é‡è¦æ€§
6. å¸®åŠ©å­¦ç”Ÿç†è§£AIçš„å±€é™æ€§å’Œæ½œåœ¨é£é™©

è®°ä½:ä½ çš„å›ç­”åº”è¯¥æ—¢è§£å†³å­¦ç”Ÿçš„å…·ä½“é—®é¢˜,åˆåŸ¹å…»ä»–ä»¬å¯¹AIä¼¦ç†çš„æ„è¯†å’Œæ‰¹åˆ¤æ€§æ€ç»´ã€‚'''
    }
    
    # æ„å»ºæœ€ç»ˆçš„æ¶ˆæ¯åˆ—è¡¨
    final_messages = [final_system_prompt]
    
    # æ·»åŠ å†å²å¯¹è¯(æ’é™¤æœ€åä¸€æ¡,å› ä¸ºæˆ‘ä»¬è¦é‡æ–°æ·»åŠ )
    if len(messages) > 1:
        for msg in messages[:-1]:
            final_messages.append({
                'role': msg['role'],
                'content': msg['content']
            })
    
    # æ·»åŠ å½“å‰ç”¨æˆ·é—®é¢˜
    final_messages.append({
        'role': 'user',
        'content': user_message
    })
    
    logger.info(f"Step 2: Calling final LLM with AI Ethics guidance for student {student_id}")
    
    return call_qwen_api(
        final_messages, 
        **AGENT_CONFIG['full_response']  # max_tokens=800, timeout=60
    )


def call_srl_and_ethics_llm(messages, student_id):
    """
    Group 3: SRL + AI Ethics åŒé‡è¾…åŠ©çš„LLM - ä¸‰æ­¥çº§è”å·¥ä½œæµ
    
    å·¥ä½œæµç¨‹:
    1. å…ˆå°†å­¦ç”Ÿé—®é¢˜å‘é€ç»™ AI Ethics Instruction Agent,è·å–AIä¼¦ç†æŒ‡å¯¼
    2. å°† AI Ethics æŒ‡å¯¼å‘é€ç»™ SRL Instruction Agent,è¿›è¡ŒSRLè°ƒæ•´
    3. å°†æœ€ç»ˆæ•´åˆçš„æŒ‡å¯¼ + å­¦ç”ŸåŸå§‹é—®é¢˜ä¸€èµ·å‘é€ç»™æœ€ç»ˆ LLM
    """
    
    # æå–å­¦ç”Ÿçš„æœ€æ–°é—®é¢˜
    user_message = messages[-1]['content'] if messages and messages[-1]['role'] == 'user' else ''
    
    if not user_message:
        return call_qwen_api(messages, **AGENT_CONFIG['full_response'])
    
    # ========== æ­¥éª¤1: è°ƒç”¨ AI Ethics Instruction Agent ==========
    ethics_agent_prompt = {
        'role': 'system',
        'content': '''ä½ æ˜¯ä¸€ä¸ªAIä¼¦ç†æ•™è‚²ä¸“å®¶ã€‚

è¯·åˆ†æå­¦ç”Ÿçš„é—®é¢˜,å¹¶æä¾›ç®€çŸ­çš„AIä¼¦ç†æŒ‡å¯¼å»ºè®®(2-3å¥è¯),å¸®åŠ©å­¦ç”Ÿ:
- è¯†åˆ«AIæŠ€æœ¯ä¸­çš„æ½œåœ¨åè§å’Œå…¬å¹³æ€§é—®é¢˜
- ç†è§£æ•°æ®éšç§å’Œå®‰å…¨çš„é‡è¦æ€§
- åŸ¹å…»å¯¹AIä½¿ç”¨çš„æ‰¹åˆ¤æ€§æ€ç»´
- è®¤è¯†AIçš„ç¤¾ä¼šå½±å“å’Œè´£ä»»

åªéœ€è¦è¿”å›AIä¼¦ç†æŒ‡å¯¼å»ºè®®,ä¸è¦ç›´æ¥å›ç­”å­¦ç”Ÿçš„é—®é¢˜ã€‚'''
    }
    
    ethics_agent_messages = [
        ethics_agent_prompt,
        {'role': 'user', 'content': f'å­¦ç”Ÿé—®é¢˜: {user_message}\n\nè¯·ç»™å‡ºAIä¼¦ç†æŒ‡å¯¼å»ºè®®:'}
    ]
    
    logger.info(f"Step 1: Calling AI Ethics Instruction Agent for student {student_id}")
    
    try:
        ethics_response = call_qwen_api(
            ethics_agent_messages, 
            **AGENT_CONFIG['short_instruction']  # max_tokens=300, timeout=30
        )
        ethics_instruction = ethics_response['choices'][0]['message']['content'].strip()
        logger.info(f"AI Ethics Instruction generated: {ethics_instruction[:100]}...")
    except Exception as e:
        logger.error(f"Error calling AI Ethics agent: {e}")
        # å¦‚æœå¤±è´¥,ä½¿ç”¨é»˜è®¤æŒ‡å¯¼
        ethics_instruction = "åœ¨ä½¿ç”¨AIæŠ€æœ¯æ—¶,è¯·æ€è€ƒå¯èƒ½å­˜åœ¨çš„åè§å’Œä¼¦ç†é—®é¢˜,å¹¶è´Ÿè´£ä»»åœ°ä½¿ç”¨ã€‚"
    
    # ========== æ­¥éª¤2: è°ƒç”¨ SRL Instruction Agent å¯¹ä¼¦ç†æŒ‡å¯¼è¿›è¡Œè°ƒæ•´ ==========
    srl_agent_prompt = {
        'role': 'system',
        'content': '''ä½ æ˜¯ä¸€ä¸ªè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ (SRL)æŒ‡å¯¼ä¸“å®¶ã€‚

ä½ å°†æ”¶åˆ°ä¸€ä¸ªAIä¼¦ç†æ–¹é¢çš„æŒ‡å¯¼å»ºè®®ã€‚è¯·åŸºäºSRLåŸåˆ™å¯¹è¿™ä¸ªæŒ‡å¯¼è¿›è¡Œè°ƒæ•´å’Œæ‰©å±•,ä½¿å…¶:
- é¼“åŠ±å­¦ç”Ÿè®¾å®šå­¦ä¹ ç›®æ ‡
- å¼•å¯¼å­¦ç”Ÿç›‘æ§å’Œè¯„ä¼°è‡ªå·±çš„ç†è§£
- ä¿ƒè¿›å­¦ç”Ÿçš„å…ƒè®¤çŸ¥æ€è€ƒ
- å¸®åŠ©å­¦ç”Ÿåæ€å­¦ä¹ ç­–ç•¥

è¯·ä¿ç•™åŸæœ‰çš„AIä¼¦ç†å†…å®¹,ä½†ç”¨SRLçš„è§†è§’è¿›è¡Œé‡æ–°è¡¨è¿°å’Œæ‰©å±•(3-4å¥è¯)ã€‚'''
    }
    
    srl_agent_messages = [
        srl_agent_prompt,
        {'role': 'user', 'content': f'''å­¦ç”Ÿçš„åŸå§‹é—®é¢˜: {user_message}

AIä¼¦ç†æŒ‡å¯¼å»ºè®®:
{ethics_instruction}

è¯·åŸºäºSRLåŸåˆ™è°ƒæ•´å’Œæ‰©å±•è¿™ä¸ªæŒ‡å¯¼:'''}
    ]
    
    logger.info(f"Step 2: Calling SRL Instruction Agent to adjust ethics guidance for student {student_id}")
    
    try:
        srl_response = call_qwen_api(
            srl_agent_messages, 
            **AGENT_CONFIG['medium_instruction']  # max_tokens=400, timeout=30
        )
        final_instruction = srl_response['choices'][0]['message']['content'].strip()
        logger.info(f"Final SRL-adjusted instruction generated: {final_instruction[:100]}...")
    except Exception as e:
        logger.error(f"Error calling SRL agent: {e}")
        # å¦‚æœSRLè°ƒæ•´å¤±è´¥,ä½¿ç”¨åŸå§‹çš„ä¼¦ç†æŒ‡å¯¼
        final_instruction = ethics_instruction + " è¯·åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ç›‘æ§è‡ªå·±çš„ç†è§£,å¹¶åæ€ä½ çš„å­¦ä¹ ç­–ç•¥ã€‚"
    
    # ========== æ­¥éª¤3: è°ƒç”¨æœ€ç»ˆ LLM å›ç­”å­¦ç”Ÿé—®é¢˜ ==========
    final_system_prompt = {
        'role': 'system',
        'content': f'''ä½ æ˜¯ä¸€ä¸ªåŒæ—¶æ”¯æŒè‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ (SRL)å’ŒAIä¼¦ç†æ•™è‚²çš„AIåŠ©æ‰‹ã€‚

**æ•´åˆæŒ‡å¯¼å»ºè®®(SRL + AI Ethics):**
{final_instruction}

è¯·åœ¨å›ç­”å­¦ç”Ÿé—®é¢˜æ—¶:
1. è‡ªç„¶åœ°èå…¥ä¸Šè¿°æ•´åˆæŒ‡å¯¼å»ºè®®
2. æä¾›å‡†ç¡®ã€æœ‰å¸®åŠ©çš„ç­”æ¡ˆ
3. **SRLæ–¹é¢**: é¼“åŠ±å­¦ç”Ÿè®¾å®šå­¦ä¹ ç›®æ ‡ã€ç›‘æ§è¿›åº¦ã€åæ€ç­–ç•¥ã€æä¾›å…ƒè®¤çŸ¥æ”¯æŒ
4. **AIä¼¦ç†æ–¹é¢**: è®¨è®ºAIçš„ä¼¦ç†é—®é¢˜(åè§ã€å…¬å¹³æ€§ã€éšç§)ã€åŸ¹å…»æ‰¹åˆ¤æ€§æ€ç»´ã€å¼ºè°ƒè´Ÿè´£ä»»ä½¿ç”¨
5. å¹³è¡¡è¿™ä¸¤ä¸ªæ–¹é¢,å¸®åŠ©å­¦ç”Ÿæˆä¸ºè´Ÿè´£ä»»çš„ã€è‡ªä¸»çš„å­¦ä¹ è€…

è®°ä½:ä½ çš„å›ç­”åº”è¯¥æ—¢è§£å†³å­¦ç”Ÿçš„å…·ä½“é—®é¢˜,åˆåŒæ—¶ä¿ƒè¿›ä»–ä»¬çš„è‡ªæˆ‘è°ƒèŠ‚å­¦ä¹ èƒ½åŠ›å’ŒAIä¼¦ç†æ„è¯†ã€‚'''
    }
    
    # æ„å»ºæœ€ç»ˆçš„æ¶ˆæ¯åˆ—è¡¨
    final_messages = [final_system_prompt]
    
    # æ·»åŠ å†å²å¯¹è¯(æ’é™¤æœ€åä¸€æ¡,å› ä¸ºæˆ‘ä»¬è¦é‡æ–°æ·»åŠ )
    if len(messages) > 1:
        for msg in messages[:-1]:
            final_messages.append({
                'role': msg['role'],
                'content': msg['content']
            })
    
    # æ·»åŠ å½“å‰ç”¨æˆ·é—®é¢˜
    final_messages.append({
        'role': 'user',
        'content': user_message
    })
    
    logger.info(f"Step 3: Calling final LLM with integrated SRL+Ethics guidance for student {student_id}")
    
    return call_qwen_api(
        final_messages, 
        **AGENT_CONFIG['full_response']  # max_tokens=800, timeout=60
    )


def call_original_llm(messages, student_id):
    """
    Group 4: åŸå§‹LLMï¼ˆå¯¹ç…§ç»„ï¼‰
    ä¸æ·»åŠ ä»»ä½•ç‰¹æ®Šçš„ç³»ç»Ÿæç¤ºè¯
    """
    return call_qwen_api(messages, **AGENT_CONFIG['full_response'])


def route_llm_call(llm_type, messages, student_id):
    """æ ¹æ®ç»„ç±»å‹è·¯ç”±åˆ°å¯¹åº”çš„LLMè°ƒç”¨å‡½æ•°"""
    llm_handlers = {
        'srl': call_srl_llm,
        'ai_ethics': call_ai_ethics_llm,
        'srl_and_ethics': call_srl_and_ethics_llm,
        'original': call_original_llm
    }
    
    handler = llm_handlers.get(llm_type, call_original_llm)
    return handler(messages, student_id)

# ================== èŠå¤©æ¥å£ ==================
@app.route('/chat', methods=['POST'])
def chat():
    """å¤„ç†èŠå¤©æ¶ˆæ¯"""
    try:
        if not request.is_json:
            return jsonify({
                'error': 'Content-Type must be application/json',
                'success': False
            }), 400
        
        data = request.get_json()
        user_message = data.get('message', '').strip()
        session_id = data.get('session_id')
        student_id = data.get('student_id', 'default')
        llm_type = data.get('llm_type', 'original')
        context = data.get('context', [])
        
        if not user_message or len(user_message) > 2000:
            return jsonify({
                'error': 'Invalid message',
                'success': False
            }), 400
        
        if not API_KEY:
            return jsonify({
                'error': 'API configuration error',
                'success': False
            }), 500
        
        # åˆ›å»ºæ–°å¯¹è¯
        if not session_id:
            session_id = str(uuid.uuid4())
            group_info = get_student_group(student_id) or {'group_id': 'unknown', 'group_name': 'unknown'}
            
            redis_db.create_conversation(
                session_id, 
                student_id, 
                group_info, 
                llm_type,
                user_message[:30] + ('...' if len(user_message) > 30 else '')
            )
            
            logger.info(f"Conversation {session_id} created")
        
        # è·å–å½“å‰å¯¹è¯
        conversation = redis_db.get_conversation(session_id)
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
        messages = []
        if conversation and conversation.get('messages'):
            # ä½¿ç”¨ä¹‹å‰çš„å¯¹è¯å†å²ï¼ˆæœ€å¤š20æ¡ï¼‰
            for msg in conversation['messages'][-20:]:
                messages.append({
                    'role': msg['role'],
                    'content': msg['content']
                })
        
        # ç¡®ä¿æœ€åä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯
        if not messages or messages[-1]['role'] != 'user':
            messages.append({'role': 'user', 'content': user_message})
        
        logger.info(f"Calling LLM for student {student_id}, type: {llm_type}")
        
        # è°ƒç”¨LLM
        result = route_llm_call(llm_type, messages, student_id)
        
        if 'choices' not in result or not result['choices']:
            logger.error(f"Invalid API response: {result}")
            return jsonify({
                'error': 'Invalid response from AI service',
                'success': False
            }), 502
        
        ai_reply = result['choices'][0]['message']['content'].strip()
        
        if not ai_reply:
            return jsonify({
                'error': 'Empty response from AI service',
                'success': False
            }), 502
        
        # ä¿å­˜æ¶ˆæ¯åˆ°Redis
        user_word_count = len(user_message.split())
        ai_word_count = len(ai_reply.split())
        
        redis_db.add_message_to_conversation(session_id, 'user', user_message, user_word_count)
        redis_db.add_message_to_conversation(session_id, 'assistant', ai_reply, ai_word_count)
        
        # æ›´æ–°å­¦ç”Ÿç»Ÿè®¡
        redis_db.add_to_student_stats(student_id, 2, 0)  # 2æ¡æ¶ˆæ¯
        
        logger.info(f"Successfully generated AI response for {llm_type}")
        
        return jsonify({
            'reply': ai_reply,
            'success': True,
            'session_id': session_id
        })
        
    except Exception as e:
        logger.error(f"Chat error: {e}")
        return jsonify({
            'error': 'An unexpected error occurred.',
            'success': False
        }), 500
# ========== æ•°æ®å¯¼å‡ºæ¥å£ ==========

@app.route('/api/export/conversations', methods=['GET'])
def export_conversations():
    """å¯¼å‡ºæ‰€æœ‰å¯¹è¯ä¸ºCSV"""
    try:
        import pandas as pd
        from io import BytesIO
        from flask import send_file
        
        conversations = redis_db.get_all_conversations()
        
        data = []
        for conv in conversations:
            data.append({
                'conversation_id': conv['conversation_id'],
                'student_id': conv['student_id'],
                'group_id': conv['group_id'],
                'group_name': conv['group_name'],
                'llm_type': conv['llm_type'],
                'title': conv['title'],
                'created_at': conv['created_at'],
                'message_count': conv['message_count']
            })
        
        if not data:
            return jsonify({'error': 'No data to export'}), 404
        
        df = pd.DataFrame(data)
        
        output = BytesIO()
        df.to_csv(output, index=False, encoding='utf-8-sig')
        output.seek(0)
        
        return send_file(
            output,
            mimetype='text/csv',
            as_attachment=True,
            download_name=f'conversations_{datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")}.csv'
        )
    except Exception as e:
        logger.error(f"Export error: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/export/messages', methods=['GET'])
def export_messages():
    """å¯¼å‡ºæ‰€æœ‰æ¶ˆæ¯ä¸ºCSV"""
    try:
        import pandas as pd
        from io import BytesIO
        from flask import send_file
        
        messages = redis_db.get_all_messages()
        
        if not messages:
            return jsonify({'error': 'No data to export'}), 404
        
        df = pd.DataFrame(messages)
        
        output = BytesIO()
        df.to_csv(output, index=False, encoding='utf-8-sig')
        output.seek(0)
        
        return send_file(
            output,
            mimetype='text/csv',
            as_attachment=True,
            download_name=f'messages_{datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")}.csv'
        )
    except Exception as e:
        logger.error(f"Export error: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/export/statistics', methods=['GET'])
def export_statistics():
    """å¯¼å‡ºå­¦ç”Ÿç»Ÿè®¡æ•°æ®ä¸ºCSV"""
    try:
        import pandas as pd
        from io import BytesIO
        from flask import send_file
        
        stats = redis_db.export_statistics()
        
        if not stats:
            return jsonify({'error': 'No data to export'}), 404
        
        df = pd.DataFrame(stats)
        
        output = BytesIO()
        df.to_csv(output, index=False, encoding='utf-8-sig')
        output.seek(0)
        
        return send_file(
            output,
            mimetype='text/csv',
            as_attachment=True,
            download_name=f'statistics_{datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")}.csv'
        )
    except Exception as e:
        logger.error(f"Export error: {e}")
        return jsonify({'error': str(e)}), 500

# ================== ä¼šè¯ç®¡ç† ==================

@app.route('/api/sessions', methods=['GET'])
def get_sessions():
    """è·å–ä¼šè¯åˆ—è¡¨ - ä» Redis è·å–"""
    try:
        student_id = request.args.get('student_id')
        
        if not student_id:
            return jsonify({'error': 'ç¼ºå°‘å­¦ç”ŸID', 'success': False}), 400
        
        # ä» Redis è·å–è¯¥å­¦ç”Ÿçš„æ‰€æœ‰å¯¹è¯
        all_conversations = redis_db.get_all_conversations()
        
        # ç­›é€‰è¯¥å­¦ç”Ÿçš„å¯¹è¯
        student_sessions = []
        for conv in all_conversations:
            if conv.get('student_id') == student_id:
                session_info = {
                    'id': conv['conversation_id'],
                    'title': conv.get('title', 'æ— æ ‡é¢˜å¯¹è¯'),
                    'created_at': conv['created_at'],
                    'message_count': conv['message_count']
                }
                
                # æ·»åŠ æœ€åä¸€æ¡æ¶ˆæ¯é¢„è§ˆ
                if conv.get('messages'):
                    last_msg = conv['messages'][-1]
                    session_info['last_message'] = last_msg['content'][:50] + ('...' if len(last_msg['content']) > 50 else '')
                else:
                    session_info['last_message'] = ''
                
                student_sessions.append(session_info)
        
        # æŒ‰åˆ›å»ºæ—¶é—´å€’åºæ’åˆ—
        student_sessions.sort(key=lambda x: x['created_at'], reverse=True)
        
        return jsonify({
            'sessions': student_sessions,
            'success': True
        })
        
    except Exception as e:
        logger.error(f"Error getting sessions: {e}")
        return jsonify({'error': str(e), 'success': False}), 500


@app.route('/api/sessions/<session_id>', methods=['GET'])
def get_session(session_id):
    """è·å–ç‰¹å®šä¼šè¯çš„è¯¦ç»†ä¿¡æ¯ - ä» Redis è·å–"""
    try:
        # ä» Redis è·å–
        session = redis_db.get_conversation(session_id)
        
        if not session:
            return jsonify({
                'error': 'ä¼šè¯ä¸å­˜åœ¨',
                'success': False
            }), 404
        
        return jsonify({
            'session': session,
            'success': True
        })
        
    except Exception as e:
        logger.error(f"Error getting session: {e}")
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


@app.route('/api/sessions/<session_id>', methods=['DELETE'])
def delete_session(session_id):
    """åˆ é™¤ä¼šè¯ - ä» Redis åˆ é™¤"""
    try:
        if not redis_db.available:
            return jsonify({
                'error': 'Redis ä¸å¯ç”¨',
                'success': False
            }), 503
        
        # å…ˆæ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨
        session = redis_db.get_conversation(session_id)
        if not session:
            return jsonify({
                'error': 'ä¼šè¯ä¸å­˜åœ¨',
                'success': False
            }), 404
        
        # ä» Redis åˆ é™¤
        key = f"conversation:{session_id}"
        success = redis_db._delete(key)
        
        if success:
            return jsonify({
                'message': 'ä¼šè¯å·²åˆ é™¤',
                'success': True
            })
        else:
            return jsonify({
                'error': 'åˆ é™¤å¤±è´¥',
                'success': False
            }), 500
            
    except Exception as e:
        logger.error(f"Error deleting session: {e}")
        return jsonify({
            'error': str(e),
            'success': False
        }), 500


@app.route('/api/sessions', methods=['POST'])
def create_session():
    """åˆ›å»ºæ–°ä¼šè¯ - è¿™ä¸ªå‡½æ•°ç°åœ¨ä¸»è¦ç”± /chat æ¥å£è‡ªåŠ¨è°ƒç”¨"""
    try:
        data = request.json or {}
        student_id = data.get('student_id')
        llm_type = data.get('llm_type', 'original')
        title = data.get('title', 'æ–°å¯¹è¯')
        
        if not student_id:
            return jsonify({
                'error': 'ç¼ºå°‘å­¦ç”ŸID',
                'success': False
            }), 400
        
        session_id = str(uuid.uuid4())
        group_info = get_student_group(student_id) or {
            'group_id': 'unknown',
            'group_name': 'unknown'
        }
        
        # åœ¨ Redis ä¸­åˆ›å»ºæ–°ä¼šè¯
        redis_db.create_conversation(
            session_id,
            student_id,
            group_info,
            llm_type,
            title
        )
        
        return jsonify({
            'session_id': session_id,
            'message': 'æ–°ä¼šè¯å·²åˆ›å»º',
            'success': True
        })
        
    except Exception as e:
        logger.error(f"Error creating session: {e}")
        return jsonify({
            'error': str(e),
            'success': False
        }), 500

@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'error': 'Endpoint not found',
        'available_endpoints': ['/', '/login', '/chat', '/health', '/api/sessions', '/api/login']
    }), 404

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"Internal server error: {error}")
    return jsonify({'error': 'Internal server error'}), 500

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug = os.environ.get('FLASK_ENV') == 'development'
    
    logger.info(f"Starting AI Chat on port {port}")
    logger.info(f"API Key configured: {bool(API_KEY)}")
    logger.info(f"Student groups loaded: {len(STUDENTS_CONFIG.get('groups', {}))}")
    
    app.run(debug=debug, port=port, host='0.0.0.0')